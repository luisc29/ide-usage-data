\chapter{Data and Methodology}
\label{ch:intro}

\section{Description of the data}
In this section we introduce the data with which we worked in terms of the source, attributes and special characteristics. Although they come from different contexts, they represent the same kind of information.

\subsection{Eclipse Usage Data Collector}
The Usage Data Collector (UDC) dataset is a large compendium of information about interaction data from users of Eclipse, collected from December 2008 to August 2010, with the intention to keep track of how programmers are using the IDE. The framework listens to the events triggered by the user or the system, such as: edition and navigation commands; the startup of a plug in; or the closing of the platform. To be more specific, UDC collects information about loaded bundles, commands accessed via keyboard shortcuts, actions invoked via menu or tool-bars, perspective changes, view usage and editor usage. The UDC is a large dataset that contains information of around 1,800,000 users, and has a total of 2,323,233,101 unique rows with 5 attributes each. Table \ref{tbl:att_udc} shows a description of the attributes.


\begin{table}[ht!]
	\small
	\caption{Attributes of the UDC dataset. }
	\label{tbl:att_udc}
	\centering
	\begin{tabular}{p{2.5cm}|p{7cm}} 
		\hline 
		\emph{Attribute} & \emph{Description} \\  
		\hline 
		\hline 
		UserId &  Unique number that identifies a user \\
		\hline
		What & The action of the event (deactivated, activated, opened, executed, etc.)  \\
		\hline
		Kind & What kind of event was executed (workbench, view, command, etc.)  \\
		\hline
		BundleId & Description of the event's package  \\
		\hline
		BundleVersion & Version of the bundle's event  \\
		\hline
		Description & Description of the event\\
		\hline
		Datetime & Date and time in UNIX format\\
		\hline
	\end{tabular}
	
\end{table}

We used the pre-processed version of the data that is published on Google BigQuery, by Murphy-Hill et al. \cite{SnipesETALASD}. This is an alternative version of the original UDC dataset, which is cleaned and preprocessed, so that the transformation phase is simpler and focused on our needs. Due to the magnitude of the dataset we only worked on a fragment of it. 

We took a subset of the data from 1,000 random users. We delimited the query to obtain only those events dispatched by the user, ignoring system events. We also ignored the bundle version and transformed the UNIX date into a more legible datetime format. From this query we extracted 4,321,349 unique events, which are around $0.18\%$ of the whole dataset. Also, we only selected the attributes UserId, What, Kind, Description and Datetime.

\subsection{Codealike and ABB}
Codealike \cite{CLQ15} is a tool that monitors the activity of the user and later offers analytics and insight about the programmer's productivity and working patterns. This tool is installed in the IDE (Eclipse and Visual Studio) and listens the events executed by the user similar to UDC. It captures almost the same kind of events like edition, navigation and tool usage. Shortly after the capture of events, the user can observe information derived from his activity through a website.

Corvalius (the Argentinian company that created Codealike) is collaborating with ABB, a multinational corporation operating mainly in robotics, power and automation technology areas. The ABB's Software Engineering Research Group is using Codealike to obtain information from its developers with the objective of improving productivity and software quality. We had access to a dataset corresponding to the monitoring of 87 programmers between May and October of 2015 comprising 15,597,697 unique events.

\begin{table}[ht!]
	\small
	\caption{Attributes of the ABB dataset. }
	\label{tbl:att_abb}
	\centering
	\begin{tabular}{p{2.5cm}|p{7cm}} 
		\hline 
		\emph{Attribute} & \emph{Description} \\  
		\hline 
		\hline 
		Username &  Unique identifier of the user \\
		\hline
		Timestamp & Date and time of the execution  \\
		\hline
		Event & Identifier of the event's description  \\
		\hline
		Category & Unique identifier of the event's category \\
		\hline
	\end{tabular}
	
\end{table}

The actual description of the events is stored on a different file, so we use the values of the Category and Events attributes to extract the proper description. Aside from that, we use all events and attributes of the dataset. From hereafter, this dataset will be referred as ABB.

\section{Methodology}
We followed the steps described by the \emph{Knowledge Discovery in Databases} process \cite{FPG96}, a set of iterative steps composed of Selection, Preprocessing, Transformation, Data Mining and Interpretation. The Selection was covered by the last two sections and the following sections will describe the tasks performed during the Preprocessing and Transformation steps. In the latter Chapters we will give details about the Data Mining and Interpretation steps.

\subsection{Preprocessing}
During the Preprocessing stage we performed mainly two tasks: data cleaning and classification. The cleaning tasks are trivial, for the data is in overall good shape. However classifying the events is a complicated task that requires careful inspection and multiple iterations. The tasks involving data cleaning diverge between datasets, so we give details about this step separately. But the classification of events follows the same process for both datasets and is described afterwards.

\subsubsection{UDC}
First, we added a field with the duration of every event (time elapsing between one event and the next one, used to determine where interruptions take place and sessions end) and an ID to identify the different working sessions present on the data. For the latter, we sorted the data by UserId and Timestamp. This was required because, by default, the user's data is mixed and we need it not only chronologically correct but also sorted by users to tag the working sessions of every user without interferences. We also filled the description for the events that indicate the activation or deactivation of the Eclipse's workbench, and they were the only ones that had this issue.

\subsubsection{ABB}
The Preprocessing for ABB is also simple. As with UDC, we added a duration in seconds and an ID to every event. Then, we extracted the Description from a second dataset, according to the Event and Category, and created a new attribute. We changed the Description to lowercases and removed curly braces and other special characters. 

An interesting feature of this dataset is that plenty of data seems to be somewhat systematic, with a certain event executed every 5 minutes. We do not know in what scenarios this kind of activity is recorded so we decided to remove the observations. Finally, we ordered the data by Username and Datetime.

\subsection{Classification of events}
To classify the events, we look into the description to see what it can tell us about the event. We worked with two kinds of classifications:
\begin{itemize}
	\item A detailed classification to tag the nature of every event.
	\item A general classification to identify between Edition and Selection events.
\end{itemize}
Having two classifications will help us provide better answers to our research questions, for some of them require doing analyses in detail and others can be seen from a general perspective. The general classification is derived from the detailed classification, so we describe the latter first in the Table \ref{tbl:detailed_events}.

\begin{table}[ht!]
	\small
	\caption{Description of the detailed classification of events. }
	\label{tbl:detailed_events}
	\centering
	\begin{tabular}{p{2cm}|p{4.5cm}|p{4.5cm}} 
		\hline 
		\emph{Classification} & \emph{Description} & \emph{Examples} \\  
		\hline 
		\hline 
		Edit-Text &  Text edition events & Copy, Paste and Delete. \\
		\hline
		Text-Nav & Events executed when navigating around text. & LineUp, LineDown and LineEnd.  \\
		\hline
		High-Nav & Navigation of high level, like around classes and views. & GoToDefinition, NextTab and GoToSuperclass \\
		\hline
		Debug & Events executed during debugging sessions. & StepInto and StepOver. \\
		\hline
		Search & Events executed when searching for objects and text. & Search, Find and FindReplace. \\
		\hline
		Refactoring & Events executed when restructuring code. & Encapsulate, Rename and MoveField. \\
		\hline
		Testing & When testing (e.g. unit tests) is executed through a framework. & ExecuteTest and TestResults. \\
		\hline
		Control & Execution of version control tasks. & Compare, ViewChanges and CommitChanges. \\
		\hline
		Clean-Build & Tasks performed by the IDE to build and execute a solution.  & Build and Run. \\
		\hline
		File & Events executed during the management of files. & Open, Close and SaveChanges. \\
		\hline
		Tools & Execution of specialized tools and plugins. & DatabaseDesigner, Codealike and UIDesigner.\\
		\hline
	\end{tabular}
	
\end{table}

To assign a a detailed classification we use the description. In both datasets the description has the format \emph{path.to.class.ListenerClass}. It contains the path to the class that works as listener of the event and executes the required task. The packages and class name give out information about the nature of the event.

With that in mind, we created a set of rules that adds a classification to every event according to the name of the class and/or the name of the path. For example, in UDC we label as Text-Nav all the events that have \emph{ui.edit.scroll} in the description, and in ABB we label as High-Nav all the events whose class name is \emph{NextTab}.

Once we added the detailed type to the events, we proceeded to assign the general type. This is easily performed by setting as Selection all the events except those who has Edit-Text, Text-Nav or Refactoring in the detailed type; this set of events describe the kind of activities performed when editing code, while the rest involve navigation around classes, views code and selection of elements in the IDE. After we assigned a general and detailed type to the events we followed to the next step of the process.

\subsection{Transformation}
From the transformation phase and on, the activities are the same for both datasets, with some changes in the parameters. The objectives of the transformation phase are creating sessions and decomposing them into chunks, or segments of smaller time than sessions.

First, we identify interruptions using the duration or time interval of every event. This is an important tasks and it is convenient to define the two kinds of interruptions we use in this work:

\begin{itemize}
	\item \textit{Interruption.} We define empirically an interruption as a pause of activity of duration $\geq 3$ minutes. This is based on previous work where we observed that short interruptions lasted usually this long \cite{GM04}. Shorter values would risk classifying periods of inactivity (such as a programmer reading source code) as interruptions.
	
	\item \textit{Prolonged interruption.} Based on additional observations from this work, we defined a prolonged interruption as one lasting for more than 12 minutes. These thresholds are also supported by the Activity Theory models of Kaptelinin and Nardi \cite{KaptelininN07}. This study presented work fragmentation at two different levels: actions and activities. Interruptions originated after a period of around three minutes of sustained attention to the previous action were considered when people were switching at the level of interactions with artifacts of people. Interruptions originated after a period of twelve minutes of sustained attention to a previous activity were considered when people were switching at the level of interactions with projects or topics.  
\end{itemize}

To identify working sessions we look for interruptions as well, but only those that last for more than 4 hours. Any segment of activity surrounded by interruptions with that duration is labeled as a session. However, in order for the segment to be valid it must be of at least 30 minutes of duration.

Then, for every session we created several time series representing the execution of events by detailed classification. Taking the minute as time unit, we counted the number of events executed on every minute and created eleven time series, where the amplitude is the number of events. The interruptions were treated differently; they are also contained in a time series of its own but the amplitude is the duration of the interruption and every observation represents the minute of occurrence. 

After that, the next step is to calculate a number of metrics for every session that measure the activity of the programmer. They can be seen from two perspectives, first the metrics for the characterization of interruptions:
\begin{itemize}
	\item \textit{Number of interruptions}:  counts all the interruptions that occur in a development session.
	\item \textit{Duration of interruption}:  it is the time duration in minutes of the each interruption. 
\end{itemize}

And the metrics that describe the productivity and activity:
\begin{itemize}
	\item \textit{Productive work time:} the duration of a development session, subtracting the duration of all the interruptions present in the session, to control for inactivity.
	\item \textit{Number of edits per minute:} the total number of edits events, divided by the productive work time to control for length of the session. This is an indicator of user activity during the session.
	\item \textit{Number of selections per minute:} it is the total number of selection events, divided by the productive work time. Also an indicator of activity.
	\item \textit{Edit ratio:} the number of edits divided by the sum of edits and selections, as used by Kersten and Murphy \cite{KM06}; an efficient developer spends less time exploring code and more time editing it.
	\item \textit{Proportion of events:} it is the count of events by detailed type divided by the total of events executed in the session. There are a total of 11 values for this metric.
\end{itemize} 

The last task of the transformation phase is to split the sessions into smaller activity frames to do analyses of the programmer's activity in detail. For that we split the time series of every session into time segments of 3 to 5 minutes of activity that we will call chunks. It was necessary to recreate the time series and metrics for the chunks. After this, every user has a set of sessions (with their respective time series) and every session a has series of chunks.

\begin{table}[ht!]
	\small
	\caption{Statistics of sessions in UDC and ABB. }
	\label{tbl:stats_sessions}
	\centering
	\begin{tabular}{p{3.5cm}|p{2cm}|p{2cm}} 
		\hline
		\emph{Statistic} & \emph{UDC} & \emph{ABB} \\
		\hline
		\hline
		Number of sessions & 6,405 & 1,182 \\
		\hline
		Number of observations & 2,848,270 & 2,449,227 \\
		\hline
		Number of users & 621 & 69 \\
		\hline
		Number of chunks & 43,769 & 23,624 \\
		\hline
		Avg. duration & 4.11 hrs. & 7.33 hrs. \\
		\hline
		Avg. productive time & 64.29 min & 166.08 min \\
		\hline
		Avg. of interruptions & 9.52 & 25.40 \\
		\hline
		Avg. duration of inte. & 18.94 min & 10.74 min \\
		\hline
	\end{tabular}
\end{table}
